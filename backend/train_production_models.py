#!/usr/bin/env python3
"""
Production Model Training Script
Train all AI/ML models with your historical sales data
"""

import asyncio
import pandas as pd
import numpy as np
import os
import logging
from typing import Dict, List, Any
from datetime import datetime
import joblib
from pathlib import Path

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/model_training.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class ProductionModelTrainer:
    """Production-ready model training pipeline"""
    
    def __init__(self, data_dir: str = "data/training"):
        self.data_dir = Path(data_dir)
        self.models_dir = Path("models/production")
        self.models_dir.mkdir(parents=True, exist_ok=True)
        
    async def train_all_models(self):
        """Train all models with production data"""
        logger.info("ğŸš€ Starting production model training pipeline...")
        
        try:
            # 1. Train Lead Scoring Models
            await self.train_lead_scoring_models()
            
            # 2. Train Conversation Analysis Models
            await self.train_conversation_models()
            
            # 3. Train Voice AI Models
            await self.train_voice_models()
            
            # 4. Train Predictive Analytics Models
            await self.train_predictive_models()
            
            # 5. Validate All Models
            await self.validate_all_models()
            
            logger.info("âœ… All models trained successfully!")
            
        except Exception as e:
            logger.error(f"âŒ Training failed: {e}")
            raise
    
    async def train_lead_scoring_models(self):
        """Train lead scoring with your historical data"""
        logger.info("ğŸ¯ Training Lead Scoring Models...")
        
        # Load your historical lead data
        leads_file = self.data_dir / "historical_leads.csv"
        
        if not leads_file.exists():
            logger.warning("ğŸ“ Creating sample lead data template...")
            self.create_sample_lead_data()
            logger.info(f"ğŸ“‹ Please populate {leads_file} with your historical lead data")
            return
        
        # Load and process data
        leads_data = pd.read_csv(leads_file)
        logger.info(f"ğŸ“Š Loaded {len(leads_data)} historical leads")
        
        # Initialize ML system
        from app.core.ml_lead_scoring import MLLeadScoringSystem
        ml_system = MLLeadScoringSystem()
        
        # Prepare features and target
        features = self.prepare_lead_features(leads_data)
        target = leads_data['converted'].astype(int)
        
        # Train models
        accuracy_scores = {}
        
        # Train Random Forest
        logger.info("ğŸŒ² Training Random Forest model...")
        rf_accuracy = ml_system.train_random_forest(features, target)
        accuracy_scores['random_forest'] = rf_accuracy
        
        # Train XGBoost
        logger.info("ğŸš€ Training XGBoost model...")
        xgb_accuracy = ml_system.train_xgboost(features, target)
        accuracy_scores['xgboost'] = xgb_accuracy
        
        # Train Neural Network
        logger.info("ğŸ§  Training Neural Network...")
        nn_accuracy = ml_system.train_neural_network(features, target)
        accuracy_scores['neural_network'] = nn_accuracy
        
        # Save models
        model_path = self.models_dir / "lead_scoring_models.pkl"
        joblib.dump(ml_system, model_path)
        
        logger.info(f"âœ… Lead Scoring Models trained successfully!")
        logger.info(f"ğŸ“Š Accuracy scores: {accuracy_scores}")
    
    async def train_conversation_models(self):
        """Train conversation analysis with your chat data"""
        logger.info("ğŸ’¬ Training Conversation Analysis Models...")
        
        conversations_file = self.data_dir / "sales_conversations.csv"
        
        if not conversations_file.exists():
            logger.warning("ğŸ“ Creating sample conversation data template...")
            self.create_sample_conversation_data()
            logger.info(f"ğŸ“‹ Please populate {conversations_file} with your conversation data")
            return
        
        # Load conversation data
        conversations = pd.read_csv(conversations_file)
        logger.info(f"ğŸ’¬ Loaded {len(conversations)} historical conversations")
        
        # Train sentiment analysis
        from textblob import TextBlob
        
        # Prepare training data for custom sentiment model
        sentiment_scores = []
        for text in conversations['conversation_text']:
            blob = TextBlob(text)
            sentiment_scores.append({
                'polarity': blob.sentiment.polarity,
                'subjectivity': blob.sentiment.subjectivity
            })
        
        # Save sentiment baseline
        sentiment_baseline = pd.DataFrame(sentiment_scores)
        sentiment_baseline.to_csv(self.models_dir / "sentiment_baseline.csv", index=False)
        
        logger.info("âœ… Conversation models trained!")
    
    async def train_voice_models(self):
        """Train voice AI with your call recordings"""
        logger.info("ğŸ¤ Training Voice AI Models...")
        
        voice_data_file = self.data_dir / "voice_call_data.csv"
        
        if not voice_data_file.exists():
            logger.warning("ğŸ“ Creating sample voice data template...")
            self.create_sample_voice_data()
            logger.info(f"ğŸ“‹ Please populate {voice_data_file} with your call data")
            return
        
        voice_data = pd.read_csv(voice_data_file)
        logger.info(f"ğŸ¤ Loaded {len(voice_data)} voice samples")
        
        # Train emotion classification
        emotion_model = self.train_emotion_classifier(voice_data)
        
        # Save voice models
        joblib.dump(emotion_model, self.models_dir / "voice_emotion_model.pkl")
        
        logger.info("âœ… Voice AI models trained!")
    
    async def train_predictive_models(self):
        """Train predictive analytics with deal data"""
        logger.info("ğŸ”® Training Predictive Analytics Models...")
        
        deals_file = self.data_dir / "historical_deals.csv"
        
        if not deals_file.exists():
            logger.warning("ğŸ“ Creating sample deals data template...")
            self.create_sample_deals_data()
            logger.info(f"ğŸ“‹ Please populate {deals_file} with your deal data")
            return
        
        deals_data = pd.read_csv(deals_file)
        logger.info(f"ğŸ’° Loaded {len(deals_data)} historical deals")
        
        # Train revenue forecasting
        from app.core.predictive_analytics import PredictiveAnalytics
        predictive_system = PredictiveAnalytics()
        
        # Prepare time series data
        revenue_data = self.prepare_revenue_time_series(deals_data)
        
        # Train forecasting model
        forecast_model = predictive_system.train_revenue_forecasting(revenue_data)
        
        # Save predictive models
        joblib.dump(forecast_model, self.models_dir / "revenue_forecast_model.pkl")
        
        logger.info("âœ… Predictive models trained!")
    
    def create_sample_lead_data(self):
        """Create sample lead data template"""
        sample_data = {
            'lead_id': ['L001', 'L002', 'L003', 'L004', 'L005'],
            'company_size': ['51-200', '201-500', '11-50', '501-1000', '51-200'],
            'industry': ['Technology', 'Healthcare', 'Finance', 'Retail', 'Manufacturing'],
            'job_title': ['VP Sales', 'CTO', 'Director', 'Manager', 'VP Marketing'],
            'email_engagement_rate': [0.45, 0.67, 0.23, 0.78, 0.56],
            'website_visits': [15, 28, 8, 35, 22],
            'content_downloads': [3, 7, 1, 9, 5],
            'meeting_acceptance_rate': [0.8, 0.9, 0.4, 1.0, 0.7],
            'response_time_hours': [2.5, 1.2, 8.0, 0.5, 3.2],
            'lead_source': ['LinkedIn', 'Website', 'Email', 'Referral', 'Event'],
            'annual_revenue': [5000000, 15000000, 1000000, 50000000, 8000000],
            'number_of_employees': [150, 350, 25, 800, 180],
            'decision_maker': [True, True, False, True, True],
            'budget_indicated': [True, False, False, True, True],
            'timeline': ['3 months', '6 months', '1 year', '1 month', '6 months'],
            'previous_interactions': [8, 15, 3, 22, 12],
            'competitor_mentions': [1, 0, 2, 1, 0],
            'urgency_score': [0.7, 0.4, 0.2, 0.9, 0.6],
            'converted': [1, 0, 0, 1, 1],  # Target variable
            'deal_value': [75000, 0, 0, 150000, 90000],
            'conversion_days': [45, 0, 0, 21, 67]
        }
        
        df = pd.DataFrame(sample_data)
        df.to_csv(self.data_dir / "historical_leads.csv", index=False)
        
        logger.info("ğŸ“ Created sample lead data template")
    
    def create_sample_conversation_data(self):
        """Create sample conversation data template"""
        sample_conversations = {
            'conversation_id': ['C001', 'C002', 'C003', 'C004', 'C005'],
            'conversation_text': [
                "I'm very interested in your solution. Can you tell me more about pricing?",
                "This looks good but I need to discuss with my team first.",
                "I'm not sure if this fits our budget requirements.",
                "This is exactly what we've been looking for! When can we start?",
                "I have some concerns about the implementation timeline."
            ],
            'sentiment_label': ['positive', 'neutral', 'negative', 'very_positive', 'concerned'],
            'objections': [['price'], ['team_approval'], ['budget'], [], ['timeline']],
            'buying_signals': [['interested', 'pricing'], ['considering'], [], ['ready', 'start'], ['implementation']],
            'outcome': ['qualified', 'follow_up', 'lost', 'won', 'nurture'],
            'deal_closed': [False, False, False, True, False]
        }
        
        df = pd.DataFrame(sample_conversations)
        df.to_csv(self.data_dir / "sales_conversations.csv", index=False)
        
        logger.info("ğŸ“ Created sample conversation data template")
    
    def create_sample_voice_data(self):
        """Create sample voice data template"""
        sample_voice = {
            'call_id': ['V001', 'V002', 'V003', 'V004', 'V005'],
            'audio_file_path': ['calls/call001.wav', 'calls/call002.wav', 'calls/call003.wav', 'calls/call004.wav', 'calls/call005.wav'],
            'emotion_label': ['confident', 'concerned', 'excited', 'frustrated', 'interested'],
            'energy_level': [0.7, 0.4, 0.9, 0.3, 0.6],
            'speaking_rate': [150, 120, 180, 100, 140],
            'call_outcome': ['positive', 'neutral', 'very_positive', 'negative', 'positive'],
            'engagement_score': [0.8, 0.5, 0.95, 0.2, 0.7]
        }
        
        df = pd.DataFrame(sample_voice)
        df.to_csv(self.data_dir / "voice_call_data.csv", index=False)
        
        logger.info("ğŸ“ Created sample voice data template")
    
    def create_sample_deals_data(self):
        """Create sample deals data template"""
        sample_deals = {
            'deal_id': ['D001', 'D002', 'D003', 'D004', 'D005'],
            'deal_value': [75000, 150000, 45000, 200000, 90000],
            'close_date': ['2024-01-15', '2024-02-20', '2024-01-30', '2024-03-10', '2024-02-05'],
            'sales_cycle_days': [45, 67, 32, 89, 56],
            'lead_score': [87, 93, 72, 96, 84],
            'industry': ['Technology', 'Healthcare', 'Finance', 'Retail', 'Manufacturing'],
            'company_size': ['51-200', '201-500', '11-50', '501-1000', '51-200'],
            'sales_rep': ['Rep1', 'Rep2', 'Rep1', 'Rep3', 'Rep2'],
            'deal_stage': ['Closed Won', 'Closed Won', 'Closed Won', 'Closed Won', 'Closed Won']
        }
        
        df = pd.DataFrame(sample_deals)
        df.to_csv(self.data_dir / "historical_deals.csv", index=False)
        
        logger.info("ğŸ“ Created sample deals data template")
    
    def prepare_lead_features(self, leads_data: pd.DataFrame) -> pd.DataFrame:
        """Prepare features for lead scoring model"""
        # Encode categorical variables
        categorical_columns = ['company_size', 'industry', 'job_title', 'lead_source', 'timeline']
        
        for col in categorical_columns:
            if col in leads_data.columns:
                leads_data[f'{col}_encoded'] = pd.factorize(leads_data[col])[0]
        
        # Select numeric features
        feature_columns = [
            'email_engagement_rate', 'website_visits', 'content_downloads',
            'meeting_acceptance_rate', 'response_time_hours', 'annual_revenue',
            'number_of_employees', 'previous_interactions', 'competitor_mentions',
            'urgency_score'
        ]
        
        # Add encoded categorical features
        encoded_columns = [f'{col}_encoded' for col in categorical_columns if col in leads_data.columns]
        feature_columns.extend(encoded_columns)
        
        # Add boolean features
        boolean_columns = ['decision_maker', 'budget_indicated']
        for col in boolean_columns:
            if col in leads_data.columns:
                leads_data[col] = leads_data[col].astype(int)
                feature_columns.append(col)
        
        return leads_data[feature_columns].fillna(0)
    
    def prepare_revenue_time_series(self, deals_data: pd.DataFrame) -> pd.DataFrame:
        """Prepare time series data for revenue forecasting"""
        deals_data['close_date'] = pd.to_datetime(deals_data['close_date'])
        
        # Aggregate by month
        monthly_revenue = deals_data.groupby(deals_data['close_date'].dt.to_period('M')).agg({
            'deal_value': 'sum',
            'deal_id': 'count'
        }).reset_index()
        
        monthly_revenue.columns = ['month', 'revenue', 'deals_count']
        monthly_revenue['month'] = monthly_revenue['month'].astype(str)
        
        return monthly_revenue
    
    def train_emotion_classifier(self, voice_data: pd.DataFrame):
        """Train emotion classification model"""
        from sklearn.ensemble import RandomForestClassifier
        from sklearn.preprocessing import LabelEncoder
        
        # Simple emotion classifier based on voice features
        features = voice_data[['energy_level', 'speaking_rate', 'engagement_score']].fillna(0)
        
        le = LabelEncoder()
        emotions = le.fit_transform(voice_data['emotion_label'])
        
        model = RandomForestClassifier(n_estimators=100, random_state=42)
        model.fit(features, emotions)
        
        return {'model': model, 'label_encoder': le}
    
    async def validate_all_models(self):
        """Validate all trained models"""
        logger.info("ğŸ” Validating all trained models...")
        
        validation_results = {}
        
        # Validate lead scoring
        lead_model_path = self.models_dir / "lead_scoring_models.pkl"
        if lead_model_path.exists():
            validation_results['lead_scoring'] = "âœ… Available"
        else:
            validation_results['lead_scoring'] = "âŒ Missing"
        
        # Validate conversation models
        sentiment_path = self.models_dir / "sentiment_baseline.csv"
        if sentiment_path.exists():
            validation_results['conversation'] = "âœ… Available"
        else:
            validation_results['conversation'] = "âŒ Missing"
        
        # Validate voice models
        voice_model_path = self.models_dir / "voice_emotion_model.pkl"
        if voice_model_path.exists():
            validation_results['voice_ai'] = "âœ… Available"
        else:
            validation_results['voice_ai'] = "âŒ Missing"
        
        # Validate predictive models
        forecast_model_path = self.models_dir / "revenue_forecast_model.pkl"
        if forecast_model_path.exists():
            validation_results['predictive'] = "âœ… Available"
        else:
            validation_results['predictive'] = "âŒ Missing"
        
        logger.info("ğŸ“Š Model Validation Results:")
        for model_type, status in validation_results.items():
            logger.info(f"   {model_type}: {status}")
        
        return validation_results

async def main():
    """Main training function"""
    print("ğŸš€ Advanced AI/ML Sales Automation - Production Model Training")
    print("=" * 70)
    
    # Ensure directories exist
    os.makedirs("data/training", exist_ok=True)
    os.makedirs("logs", exist_ok=True)
    
    trainer = ProductionModelTrainer()
    
    try:
        await trainer.train_all_models()
        
        print("\nğŸ‰ TRAINING COMPLETE!")
        print("=" * 50)
        print("âœ… All models trained successfully")
        print("ğŸ“ Models saved to: models/production/")
        print("ğŸ“‹ Training logs: logs/model_training.log")
        print("\nğŸš€ Your system is now production-ready!")
        
    except Exception as e:
        logger.error(f"âŒ Training failed: {e}")
        print(f"\nâŒ Training failed: {e}")
        print("ğŸ“‹ Check logs/model_training.log for details")

if __name__ == "__main__":
    asyncio.run(main())